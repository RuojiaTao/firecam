# Copyright 2018 The Fuego Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
"""
@author: Kinshuk Govil

This is the main code for reading images from webcams and detecting fires

"""

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import os
import sys
fuegoRoot = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, os.path.join(fuegoRoot, 'lib'))
sys.path.insert(0, fuegoRoot)
import settings
settings.fuegoRoot = fuegoRoot
import collect_args
import goog_helper
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # quiet down tensorflow logging (must be done before tf_helper)
import db_manager
import email_helper
import sms_helper
import img_archive


import logging
import pathlib
import tempfile
import shutil
import time, datetime, dateutil.parser
import random
import hashlib
from urllib.request import urlretrieve
from PIL import Image, ImageFile, ImageDraw, ImageFont
from detection_policies.inception_and_threshold import InceptionV3AndHistoricalThreshold
ImageFile.LOAD_TRUNCATED_IMAGES = True
import numpy as np


def getNextImage(dbManager, cameras, cameraID=None, sequence_length=1, sequence_interval=None):
    """Gets the next image to check for smoke

    Uses a shared counter being updated by all cooperating detection processes
    to index into the list of cameras to download the image to a local
    temporary directory

    Args:
        dbManager (DbManager):
        cameras (list): list of cameras
        cameraID (str): optional specific camera to get image from

    Returns:
        Tuple containing camera name, current timestamp, and filepath of the image
    """
    if getNextImage.tmpDir == None:
        getNextImage.tmpDir = tempfile.TemporaryDirectory()
        logging.warning('TempDir %s', getNextImage.tmpDir.name)

    #determine which camera to use
    if cameraID:
        camera = list(filter(lambda x: x['name'] == cameraID, cameras))[0]
    else:
        index = dbManager.getNextSourcesCounter() % len(cameras)
        camera = cameras[index]

    timestamp = int(time.time())
    imgPath = img_archive.getImgPath(getNextImage.tmpDir.name, camera['name'], timestamp)
    # logging.warning('urlr %s %s', camera['url'], imgPath)
    try:
        urlretrieve(camera['url'], imgPath)
    except Exception as e:
        logging.error('Error fetching image from %s %s', camera['name'], str(e))
        return getNextImage(dbManager, cameras)
    md5 = hashlib.md5(open(imgPath, 'rb').read()).hexdigest()
    if ('md5' in camera) and (camera['md5'] == md5) and not cameraID:
        logging.warning('Camera %s image unchanged', camera['name'])
        # skip to next camera
        return getNextImage(dbManager, cameras)
    camera['md5'] = md5

    return (camera['name'], timestamp, imgPath)
getNextImage.tmpDir = None

# XXXXX Use a fixed stable directory for testing
# from collections import namedtuple
# Tdir = namedtuple('Tdir', ['name'])
# getNextImage.tmpDir = Tdir('c:/tmp/dftest')


def getNextImageFromDir(imgDirectory):
    """Gets the next image to check for smoke from given directory

    A variant of getNextImage() above but works with files already present
    on the locla filesystem.

    Args:
        imgDirectory (str): directory containing the files

    Returns:
        Tuple containing camera name, current timestamp, and filepath of the image
    """
    if getNextImageFromDir.tmpDir == None:
        getNextImageFromDir.tmpDir = tempfile.TemporaryDirectory()
        logging.warning('TempDir %s', getNextImageFromDir.tmpDir.name)
    if not getNextImageFromDir.files:
        allFiles = os.listdir(imgDirectory)
        # filter out files with _Score suffix because they contain annotated scores
        # generated by drawFireBox() function below.
        getNextImageFromDir.files = list(filter(lambda x: '_Score.jpg' not in x, allFiles))
    getNextImageFromDir.index += 1
    if getNextImageFromDir.index < len(getNextImageFromDir.files):
        fileName = getNextImageFromDir.files[getNextImageFromDir.index]
        origPath = os.path.join(imgDirectory, fileName)
        destPath = os.path.join(getNextImageFromDir.tmpDir.name, fileName)
        shutil.copyfile(origPath, destPath)
        parsed = img_archive.parseFilename(fileName)
        if not parsed:
            # failed to parse, so skip to next image
            return getNextImageFromDir(imgDirectory)
        md5 = hashlib.md5(open(destPath, 'rb').read()).hexdigest()
        return (parsed['cameraID'], parsed['unixTime'], destPath, md5)
    logging.warning('Finished processing all images in directory. Exiting')
    exit(0)
getNextImageFromDir.files = None
getNextImageFromDir.index = -1
getNextImageFromDir.tmpDir = None

def drawRect(imgDraw, x0, y0, x1, y1, width, color):
    for i in range(width):
        imgDraw.rectangle((x0+i,y0+i,x1-i,y1-i),outline=color)


def drawFireBox(imgPath, detection_spec):
    """Draw bounding box with fire detection with score on image

    Stores the resulting annotated image as new file

    Args:
        imgPath (str): filepath of the image

    Returns:
        filepath of new image file
    """
    img = Image.open(imgPath)
    imgDraw = ImageDraw.Draw(img)

    for bounding_box in detection_spec:
        x0 = bounding_box['x']
        y0 = bounding_box['y']
        x1 = bounding_box['x'] + bounding_box['width']
        y1 = bounding_box['y'] + bounding_box['height']
        centerX = (x0 + x1)/2
        centerY = (y0 + y1)/2
        color = "red"
        lineWidth=3
        drawRect(imgDraw, x0, y0, x1, y1, lineWidth, color)

        fontSize=80
        font = ImageFont.truetype(os.path.join(settings.fuegoRoot, 'lib/Roboto-Regular.ttf'), size=fontSize)
        scoreStr = '%.2f' % bounding_box['score']
        textSize = imgDraw.textsize(scoreStr, font=font)
        imgDraw.text((centerX - textSize[0]/2, centerY - textSize[1]), scoreStr, font=font, fill=color)

        # color = "blue"
        # fontSize=70
        # font = ImageFont.truetype(os.path.join(settings.fuegoRoot, 'lib/Roboto-Regular.ttf'), size=fontSize)
        # scoreStr = '%.2f' % fireSegment['HistMax']
        # textSize = imgDraw.textsize(scoreStr, font=font)
        # imgDraw.text((centerX - textSize[0]/2, centerY), scoreStr, font=font, fill=color)

    filePathParts = os.path.splitext(imgPath)
    annotatedFile = filePathParts[0] + '_Score' + filePathParts[1]
    img.save(annotatedFile, format="JPEG")
    del imgDraw
    img.close()
    return annotatedFile


def recordDetection(dbManager, service, camera, timestamp, imgPath, annotatedFile, detection_spec):
    """Record that a smoke/fire has been detected

    Record the detection with useful metrics in 'detections' table in SQL DB.
    Also, upload image file to google drive

    Args:
        dbManager (DbManager):
        service:
        camera (str): camera name
        timestamp (int):
        imgPath: filepath of the image
        annotatedFile: filepath of the image with annotated box and score
        detection_spec (list): DetectionSpec (list of bounding boxes + scores)

    Returns:
        List of Google drive IDs for the uploaded image files
    """
    logging.warning('Fire detected by camera %s, image %s, segment %s', camera, imgPath, str(detection_spec))
    # upload file to google drive detection dir
    driveFileIDs = []
    driveFile = goog_helper.uploadFile(service, settings.detectionPictures, imgPath)
    if driveFile:
        driveFileIDs.append(driveFile['id'])
    driveFile = goog_helper.uploadFile(service, settings.detectionPictures, annotatedFile)
    if driveFile:
        driveFileIDs.append(driveFile['id'])
    logging.warning('Uploaded to google drive detections folder %s', str(driveFileIDs))

    dbRow = {
        'CameraName': camera,
        'Timestamp': timestamp,
        'MinX': detection_spec['x'],
        'MinY': detection_spec['y'],
        'MaxX': detection_spec['x'] + detection_spec['width'],
        'MaxY': detection_spec['y'] + detection_spec['height'],
        'Score': detection_spec['score'],
        'ImageID': driveFileIDs[0] if driveFileIDs else ''
    }
    dbManager.add_data('detections', dbRow)
    return driveFileIDs


def checkAndUpdateAlerts(dbManager, camera, timestamp, driveFileIDs):
    """Check if alert has been recently sent out for given camera

    Args:
        dbManager (DbManager):
        camera (str): camera name
        timestamp (int):
        driveFileIDs (list): List of Google drive IDs for the uploaded image files

    Returns:
        True if this is a new alert, False otherwise
    """
    # Only alert if there has not been a detection in the last hour.  This prevents spam
    # from long lasting fires.
    sqlTemplate = """SELECT * FROM detections
    where CameraName='%s' and timestamp > %s and timestamp < %s"""
    sqlStr = sqlTemplate % (camera, timestamp - 60*60, timestamp)

    dbResult = dbManager.query(sqlStr)
    if len(dbResult) > 0:
        logging.warning('Supressing new alert due to recent detection')
        return False

    dbRow = {
        'CameraName': camera,
        'Timestamp': timestamp,
        'ImageID': driveFileIDs[0] if driveFileIDs else ''
    }
    dbManager.add_data('alerts', dbRow)
    return True


def alertFire(constants, cameraID, imgPath, annotatedFile, driveFileIDs, detection_spec, timestamp):
    """Send alerts about given fire through all channels (currently email and sms)

    Args:
        constants (dict): "global" contants
        cameraID (str): camera name
        imgPath: filepath of the original image
        annotatedFile: filepath of the annotated image
        driveFileIDs (list): List of Google drive IDs for the uploaded image files
        fireSegment (dictionary): dictionary with information for the segment with fire/smoke
        timestamp (int): time.time() value when image was taken
    """
    emailFireNotification(constants, cameraID, imgPath, annotatedFile, driveFileIDs, detection_spec, timestamp)
    smsFireNotification(constants['dbManager'], cameraID)


def emailFireNotification(constants, cameraID, imgPath, annotatedFile, driveFileIDs, detection_spec, timestamp):
    """Send an email alert for a potential new fire

    Send email with information about the camera and fire score includeing
    image attachments

    Args:
        constants (dict): "global" contants
        cameraID (str): camera name
        imgPath: filepath of the original image
        annotatedFile: filepath of the annotated image
        driveFileIDs (list): List of Google drive IDs for the uploaded image files
        fireSegment (dictionary): dictionary with information for the segment with fire/smoke
        timestamp (int): time.time() value when image was taken
    """
    dbManager = constants['dbManager']
    max_score = np.max(np.array([box['score'] for box in detection_spec]))
    subject = 'Possible (%d%%) fire in camera %s' % (int(max_score*100), cameraID)
    body = 'Please check the attached images for fire.'
    # commenting out links to google drive because they appear as extra attachments causing confusion
    # and some email recipients don't even have permissions to access drive.
    # for driveFileID in driveFileIDs:
    #     driveTempl = '\nAlso available from google drive as https://drive.google.com/file/d/%s'
    #     driveBody = driveTempl % driveFileID
    #     body += driveBody

    # emails are sent from settings.fuegoEmail and bcc to everyone with active emails in notifications SQL table
    dbResult = dbManager.getNotifications(filterActiveEmail = True)
    emails = [x['email'] for x in dbResult]
    if len(emails) > 0:
        # attach images spanning a few minutes so reviewers can evaluate based on progression
        startTimeDT = datetime.datetime.fromtimestamp(timestamp - 3*60)
        endTimeDT = datetime.datetime.fromtimestamp(timestamp - 1*60)
        with tempfile.TemporaryDirectory() as tmpDirName:
            oldImages = img_archive.getHpwrenImages(constants['googleServices'], settings, tmpDirName,
                                                    constants['camArchives'], cameraID, startTimeDT, endTimeDT, 1)
            oldImages = oldImages or []
            attachments = oldImages + [imgPath, annotatedFile]
            email_helper.sendEmail(constants['googleServices']['mail'], settings.fuegoEmail, emails, subject, body, attachments)


def smsFireNotification(dbManager, cameraID):
    """Send an sms (phone text message) alert for a potential new fire

    Args:
        dbManager (DbManager):
        cameraID (str): camera name
    """
    message = 'Fuego fire notification in camera %s. Please check email for details' % cameraID
    dbResult = dbManager.getNotifications(filterActivePhone = True)
    phones = [x['phone'] for x in dbResult]
    if len(phones) > 0:
        for phone in phones:
            sms_helper.sendSms(settings, phone, message)


def getLastScoreCamera(dbManager):
    sqlStr = "SELECT CameraName from scores order by Timestamp desc limit 1;"
    dbResult = dbManager.query(sqlStr)
    if len(dbResult) > 0:
        return dbResult[0]['CameraName']
    return None


def heartBeat(filename):
    """Inform monitor process that this detection process is alive

    Informs by updating the timestamp on given file

    Args:
        filename (str): file path of file used for heartbeating
    """
    pathlib.Path(filename).touch()

def updateTimeTracker(timeTracker, processingTime):
    """Update the time tracker data with given time to process current image

    If enough samples new samples have been reorded, resets the history and
    updates the average timePerSample

    Args:
        timeTracker (dict): tracks recent image processing times
        processingTime (float): number of seconds needed to process current image
    """
    timeTracker['totalTime'] += processingTime
    timeTracker['numSamples'] += 1
    # after N samples, update the rate to adapt to current conditions
    # N = 50 should be big enough to be stable yet small enough to adapt
    if timeTracker['numSamples'] > 50:
        timeTracker['timePerSample'] = timeTracker['totalTime'] / timeTracker['numSamples']
        timeTracker['totalTime'] = 0
        timeTracker['numSamples'] = 0
        logging.warning('New timePerSample %.2f', timeTracker['timePerSample'])


def initializeTimeTracker():
    """Initialize the time tracker

    Returns:
        timeTracker (dict):
    """
    return {
        'totalTime': 0.0,
        'numSamples': 0,
        'timePerSample': 3 # start off with estimate of 3 seconds per camera
    }

def getRandomArchivedImages(constants, cameras, startTimeDT, timeRangeSeconds):
    """Get random images from HPWREN archive matching given constraints

    Args:
        constants (dict): "global" contants
        cameras (list): list of cameras
        startTimeDT (datetime): starting time of time range
        timeRangeSeconds (int): number of seconds in time range

    Returns:
        Tuple containing camera name, current timestamp, filepath image
    """
    if getRandomArchivedImages.tmpDir == None:
        getRandomArchivedImages.tmpDir = tempfile.TemporaryDirectory()
        logging.warning('TempDir %s', getRandomArchivedImages.tmpDir.name)

    cameraID = cameras[int(len(cameras)*random.random())]['name']
    timeDT = startTimeDT + datetime.timedelta(seconds = random.random()*timeRangeSeconds)
    prevTimeDT = timeDT
    files = img_archive.getHpwrenImages(constants['googleServices'], settings, getRandomArchivedImages.tmpDir.name,
                                        constants['camArchives'], cameraID, prevTimeDT, timeDT, 1)
    # logging.warning('files %s', str(files))
    if not files:
        return None, None, None
    if len(files) > 0:
        parsedName = img_archive.parseFilename(files[0])
        return cameraID, parsedName['unixTime'], files[0]
    return None, None, None
getRandomArchivedImages.tmpDir = None

def get_specific_archived_images(cameraID, start_time, end_time, download_dir, constants, period_seconds=60):
    """
    Download historical images from archivea

    :param cameraID:
    :param start_time: beginning of search range in seconds
    :param end_time: end of search range in seconds
    :param download_dir: where the image should be downloaded to
    :param constants:
    :param period_seconds: not sure what this is...copied it from get_images.py
    :return:
    """

    # TODO: need to add filtering based on pan and azimuth

    startTimeDT = datetime.datetime.fromtimestamp(start_time)
    endTimeDT = datetime.datetime.fromtimestamp(end_time)

    assert startTimeDT.year == endTimeDT.year
    assert startTimeDT.month == endTimeDT.month
    assert startTimeDT.day == endTimeDT.day
    assert endTimeDT >= startTimeDT
    alertWildfire = False
    hpwren = False

    if cameraID.startswith('Axis-'):
        alertWildfire = True
    elif cameraID.endswith('-mobo-c'):
        hpwren = True
    else:
        logging.error('Unexpected camera ID %s.  Must start with either "Axis-" or end with "mobo-c"', cameraID)
        exit(1)

    if hpwren:
        camArchives = img_archive.getHpwrenCameraArchives(constants['googleServices']['sheet'], settings)
        gapMinutes = max(round(float(period_seconds)/60), 1) # convert to minutes and ensure at least 1 minute
        files = img_archive.getHpwrenImages(constants['googleServices'], settings, download_dir, camArchives,
                                            cameraID, startTimeDT, endTimeDT, gapMinutes)
    else:
        assert alertWildfire
        files = img_archive.getAlertImages(constants['googleServices'], constants['dbManager'], settings,
                                           download_dir, cameraID, startTimeDT, endTimeDT, period_seconds)

    if files:
        return files[0]
    else:
        logging.error('No matches for camera ID %s', cameraID)



def main():
    optArgs = [
        ["b", "heartbeat", "filename used for heartbeating check"],
        ["c", "collectPositves", "collect positive segments for training data"],
        ["d", "imgDirectory", "Name of the directory containing the images"],
        ["t", "time", "Time breakdown for processing images"],
        ["m", "minusMinutes", "(optional) subtract images from given number of minutes ago"],
        ["r", "restrictType", "Only process images from cameras of given type"],
        ["s", "startTime", "(optional) performs search with modifiedTime > startTime"],
        ["e", "endTime", "(optional) performs search with modifiedTime < endTime"],
    ]
    args = collect_args.collectArgs([], optionalArgs=optArgs, parentParsers=[goog_helper.getParentParser()])
    googleServices = goog_helper.getGoogleServices(settings, args)
    dbManager = db_manager.DbManager(sqliteFile=settings.db_file,
                                    psqlHost=settings.psqlHost, psqlDb=settings.psqlDb,
                                    psqlUser=settings.psqlUser, psqlPasswd=settings.psqlPasswd)
    cameras = dbManager.get_sources(activeOnly=True, restrictType=args.restrictType)
    startTimeDT = dateutil.parser.parse(args.startTime) if args.startTime else None
    endTimeDT = dateutil.parser.parse(args.endTime) if args.endTime else None
    timeRangeSeconds = None
    useArchivedImages = False
    camArchives = img_archive.getHpwrenCameraArchives(googleServices['sheet'], settings)
    constants = { # dictionary of constants to reduce parameters in various functions
        'args': args,
        'googleServices': googleServices,
        'camArchives': camArchives,
        'dbManager': dbManager,
    }
    if startTimeDT or endTimeDT:
        assert startTimeDT and endTimeDT
        timeRangeSeconds = (endTimeDT-startTimeDT).total_seconds()
        assert timeRangeSeconds > 0
        assert args._collect_positives
        useArchivedImages = True

    processingTimeTracker = initializeTimeTracker()
    detection_policy = InceptionV3AndHistoricalThreshold(settings, args, googleServices, dbManager)
    num_input_images = detection_policy.SEQUENCE_LENGTH
    sequence_spacing = detection_policy.SEQUENCE_SPACING_MIN
    while True:
        timeStart = time.time()

        #### Generate ImageSpec: Load sequence of one or more images, either from archives or live cameras ####
        #Start
        if useArchivedImages:
            if num_input_images != 1:
                raise Exception('Archived images do net yet work with sequnces >1')
            (cameraID, timestamp, imgPath) = getRandomArchivedImages(constants, cameras, startTimeDT, timeRangeSeconds)
            image_spec = [{}]
            image_spec[-1]['path'] = imgPath
            image_spec[-1]['timestamp'] = timestamp
            image_spec[-1]['cameraID'] = cameraID
            #TODO: this archive mode is not yet set up to work with sequences of images
            if not cameraID:
                continue  # skip to next camera
        else: # regular (non diff mode), grab image and process
            cameraID, timestamp, imgPath = getNextImage(dbManager, cameras)
            if not cameraID:
                continue # skip to next camera
            image_spec = []
            image_spec.append({'path': imgPath, 'timestamp': timestamp, 'cameraID': cameraID })
            #build the rest of the sequence, if applicable
            for images_back in range(1, num_input_images):
                time_end = timestamp - 10 - (images_back - 1) * sequence_spacing
                time_start = timestamp - 10 - (images_back) * sequence_spacing
                previous_image_path = get_specific_archived_images(cameraID, time_start, time_end,
                                                                   getNextImage.tmpDir.name, constants)
                #TODO: should be replaced when better time metadata mechanism online
                previous_timestamp = timestamp - sequence_spacing
                # add to beginning of list
                image_spec.insert(0, {'path': previous_image_path, 'timestamp': previous_timestamp, 'cameraID': cameraID} )

            if len(image_spec) != num_input_images:
                logging.warn('Coulndt find historical images for camera {} as required by DetectionPolicy. skipping')
                continue

        timeFetch = time.time()

        ##### Send loaded images to detection policy ####
        detection_spec = detection_policy.run_detection(image_spec)
        timeClassify = time.time()


        ##### If fire detected, record in database and send out alerts as needed #####
        if len(detection_spec) > 0:
            annotatedFile = drawFireBox(imgPath, detection_spec)
            driveFileIDs = recordDetection(dbManager, googleServices['drive'], cameraID, timestamp, imgPath,
                                           annotatedFile, detection_spec)
            if checkAndUpdateAlerts(dbManager, cameraID, timestamp, driveFileIDs):
                alertFire(constants, cameraID, imgPath, annotatedFile, driveFileIDs, detection_spec, timestamp)
        timePost = time.time()

        #delete image sequnce
        for image in image_spec:
            os.remove(image['path'])

        updateTimeTracker(processingTimeTracker, timePost - timeStart)
        if args.time:
            logging.warning('Timings: fetch=%.2f, classify=%.2f, post=%.2f',
                timeFetch-timeStart, timeClassify-timeFetch, timePost-timeClassify)

        if (args.heartbeat):
            heartBeat(args.heartbeat)

if __name__== "__main__":
    main()
